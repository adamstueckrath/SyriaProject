{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import core libraries \n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import ast\n",
    "import pathlib\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "# import third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from pandas import ExcelWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory path data\n",
    "twitter_data_dir = pathlib.Path('/Users/adamstueckrath/Desktop/twitter_data/')\n",
    "\n",
    "# tweets_no_rts_csv file path\n",
    "tweets_no_rts_csv = twitter_data_dir / 'tweets_no_retweets' / 'tweets_no_retweets.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_datetime(tweet_date):\n",
    "    \"\"\"\n",
    "    Turns a datetime string like this: \n",
    "    '2017-07-06T18:34:37.000Z' \n",
    "    to a Python datetime object like this -> 2017-07-06 18:34:41\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(tweet_date, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tweets into dataframe from csv file\n",
    "tweets_no_rts_df = pd.read_csv(tweets_no_rts_csv, header=0,\n",
    "                               parse_dates=['tweet_created_at'], \n",
    "                               date_parser=string_to_datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_rts_df_en = tweets_no_rts_df.copy()\n",
    "tweets_no_rts_df_en = tweets_no_rts_df_en[tweets_no_rts_df_en['tweet_lang'] =='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamstueckrath/.pyenv/versions/3.6.5/envs/syria-project-3.6.5/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    tweet = tweet.lower()\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using nltk. analysis variable returns the following dict: \n",
    "    {'neg': 0.122, 'neu': 0.641, 'pos': 0.237, 'compound': 0.4215}\n",
    "    The compound value here conveys the overall positive or negative user experience.\n",
    "    Examples: \n",
    "    https://www.programcreek.com/python/example/100005/nltk.sentiment.vader.SentimentIntensityAnalyzer\n",
    "    https://opensourceforu.com/2016/12/analysing-sentiments-nltk/\n",
    "    '''\n",
    "    analysis = analyzer.polarity_scores(clean_tweet(tweet))\n",
    "    if analysis['compound'] > 0.1:\n",
    "        return 1\n",
    "    elif analysis['compound'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_rts_df_en['tweet_text_clean'] = tweets_no_rts_df_en['tweet_text'].apply(clean_tweet)\n",
    "tweets_no_rts_df_en['tweet_text_sentiment'] = tweets_no_rts_df_en['tweet_text_clean'].apply(analyze_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638161, 31)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tweets_no_rts_df_en.copy()[:1000000]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = count_vectorizer.fit_transform(test.tweet_text)\n",
    "indexed_data = hstack((np.array(range(0,vectorized_data.shape[0]))[:,None], vectorized_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment2target(sentiment):\n",
    "    return {\n",
    "        -1: 0,\n",
    "        0: 1,\n",
    "        1: 2\n",
    "    }[sentiment]\n",
    "targets = test.tweet_text_sentiment.apply(sentiment2target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, targets_train, targets_test = train_test_split(indexed_data, targets, test_size=0.4, random_state=0)\n",
    "data_train_index = data_train[:,0]\n",
    "data_train = data_train[:,1:]\n",
    "data_test_index = data_test[:,0]\n",
    "data_test = data_test[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638161, 2986500)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638161"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamstueckrath/.pyenv/versions/3.6.5/envs/syria-project-3.6.5/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 37.56977891921997 0.6976609350931818\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# iris = datasets.load_iris()\n",
    "# X, y = iris.data, iris.target\n",
    "X, y = indexed_data, targets\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# clf = OneVsRestClassifier(SVC(kernel='linear', probability=True, class_weight='balanced'))\n",
    "# clf.fit(X, y)\n",
    "# end = time.time()\n",
    "# print (\"Single SVC\", end - start, clf.score(X,y))\n",
    "# proba = clf.predict_proba(X)\n",
    "\n",
    "# n_estimators = 10\n",
    "# start = time.time()\n",
    "# clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel='linear', probability=True, class_weight='balanced'), max_samples=1.0 / n_estimators, n_estimators=n_estimators))\n",
    "# clf.fit(X, y)\n",
    "# end = time.time()\n",
    "# print (\"Bagging SVC\", end - start, clf.score(X,y))\n",
    "# proba = clf.predict_proba(X)\n",
    "\n",
    "start = time.time()\n",
    "clf = RandomForestClassifier(min_samples_leaf=20)\n",
    "clf.fit(X, y)\n",
    "end = time.time()\n",
    "print (\"Random Forest\", end - start, clf.score(X,y))\n",
    "proba = clf.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    tweet = tweet.lower()\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analyze_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using nltk. analysis variable returns the following dict: \n",
    "    {'neg': 0.122, 'neu': 0.641, 'pos': 0.237, 'compound': 0.4215}\n",
    "    The compound value here conveys the overall positive or negative user experience.\n",
    "    Examples: \n",
    "    https://www.programcreek.com/python/example/100005/nltk.sentiment.vader.SentimentIntensityAnalyzer\n",
    "    https://opensourceforu.com/2016/12/analysing-sentiments-nltk/\n",
    "    '''\n",
    "    analysis = analyzer.polarity_scores(clean_tweet(tweet))\n",
    "    if analysis['compound'] > 0.1:\n",
    "        return 1\n",
    "    elif analysis['compound'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Assad loses 3 generals during the first week of July #Syria #RevolutionWins #militia #Free_Syrian_Army\\nhttps://t.co/5x8UbVOnH9'\n",
    "\n",
    "testing = clean_tweet(test)\n",
    "print(testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_rts_df_en = tweets_no_rts_df.copy()\n",
    "tweets_no_rts_df_en = tweets_no_rts_df_en[tweets_no_rts_df_en['tweet_lang'] =='en']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_no_rts_df_en['tweet_text_clean'] = tweets_no_rts_df_en['tweet_text'].apply(clean_tweet)\n",
    "tweets_no_rts_df_en['tweet_text_sentiment'] = tweets_no_rts_df_en['tweet_text_clean'].apply(analyze_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tweets_no_rts_df_en['tweet_text_sentiment'].value_counts().to_dict()\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = tweets_no_rts_df_en['tweet_text_clean']\n",
    "tweet_text_list = tweet_text.tolist()\n",
    "print(len(tweet_text_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
